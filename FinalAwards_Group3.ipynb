{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project-1\n",
    "#### Natural language processing \n",
    "\n",
    "##### Anupriya Dhiman\n",
    "##### Pranit Malik\n",
    "##### Sagar S\n",
    "##### Twinkle Chavda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we import all the required libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=5b81b526ef7e555afcf6043621e3d47016f97f5fc2a77aaa8b1bd2243f0db3d7\n",
      "  Stored in directory: c:\\users\\abhishek\\appdata\\local\\pip\\cache\\wheels\\25\\42\\45\\b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: spacy in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.2288.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.23.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhishek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\Abhishek\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install requests\n",
    "%pip install bs4\n",
    "%pip install json\n",
    "%pip install pandas\n",
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('punkt')\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('gg2015.json','r').read()\n",
    "data=json.loads(f)\n",
    "df=pd.DataFrame(data,columns=['text','timestamp_ms','user','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(a):\n",
    "  xyz=[]\n",
    "  data=requests.get(a).text\n",
    "  src=BeautifulSoup(data,'html.parser')\n",
    "  abc=src.find_all(class_=\"lister-item-header\")\n",
    "  for i in abc:\n",
    "    xyz.append(i.find(\"a\").text)\n",
    "  return(xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz=[]\n",
    "celeb=[]\n",
    "for i in range(1,11):\n",
    "      xyz.append(url('https://www.imdb.com/list/ls058011111/?sort=list_order,asc&mode=detail&page='+str(i)))\n",
    "for i in range(0,len(xyz)):\n",
    "    for j in range(0,len(xyz[i])):\n",
    "            celeb.append((xyz[i][j].strip('\\n')).lower().strip(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding host name from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_names():\n",
    "    pattern='([H|h]ost\\w+)\\s+\\w+\\s+\\w+\\s+\\w+\\s+\\w+\\s+\\w+|([H|h]osted)\\s+[B\\b]y\\s+\\w+'\n",
    "    b=[]\n",
    "    for i in range(0,len(df)):\n",
    "        a=re.search(pattern,df.text[i])\n",
    "        if a:\n",
    "            b.append(a.group())\n",
    " \n",
    "    p=[]\n",
    "    for i in range(0,len(b)):\n",
    "        \n",
    "        p.append(nlp(b[i]).ents)\n",
    "    n=[]\n",
    "    for k in range(0,len(p)):\n",
    "        n.append(list(p[k]))\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "\n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>1000:\n",
    "            print(i)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the award name via Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def award_names():\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "content=requests.get('https://en.wikipedia.org/wiki/Golden_Globe_Awards').text\n",
    "soup=BeautifulSoup(content,'html.parser')\n",
    "data1 = soup.find('h3')\n",
    "uls=[]\n",
    "lis=[]\n",
    "award=[]\n",
    "count=0\n",
    "\n",
    "for nextSibling in data1.findNextSiblings():\n",
    "    if nextSibling.name == 'ul'and count<2:\n",
    "        uls.append(nextSibling)\n",
    "        count+=1\n",
    "        \n",
    "\n",
    "for ul in uls:\n",
    "    for li in ul.findAll('li'):\n",
    "        lis.append(li)\n",
    "for li in lis:\n",
    "    award.append(li.text.split(':')[0])\n",
    "print(award)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Award List Via RegularExpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def award_names1():\n",
    "import re\n",
    "a=[]\n",
    "pattern='(Best.*Picture|Best.*Drama|Best.*Musical|Best.*Comedy|Best.*Television|Best.*Animated|Best.*Language|Best.*Director|Best.*Screenplay|Best.*Score|Best.*Song|Best.*Film|Best.*Series)'\n",
    "for i in range(0,len(df)):\n",
    "    a.append(re.findall(pattern,df.text[i]))\n",
    "\n",
    "str1=[]\n",
    "str2=[]\n",
    "str3={}\n",
    " \n",
    "for j in range(0,len(a)):\n",
    "    for k in range(0,len(a[j])):\n",
    "        str1.append(a[j][k])\n",
    "        \n",
    "for i in str1:\n",
    "    if i not in str2:\n",
    "        str2.append(i)\n",
    "for y in range(0,len(str2)):\n",
    "    str3[str2[y]]=str1.count(str2[y]) \n",
    "\n",
    "\n",
    "for i,j in str3.items():\n",
    "    if j>900:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_names1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding presenters from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presenters():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'.*[P|p]resented\\s+[B|b]y.*|.*[Present].*|Pres.*'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "   \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presenters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nominees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nominees():\n",
    "    n=[]\n",
    "    pattern=r'[N|n]ominees|[N|n]ominee|[N|n]ominated|[N|n]ominating|[N|n]omination'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nominees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the winners from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winner of Best Drama Motion Picture award - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drama_picture():\n",
    "    n=[]\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    pattern=r'[W|w]in.*[B|b]est.*[M|m]otion.*[P|p]icture.*[D|d]rama|[P|p]icture.*[D|d]rama.*[Ww]in.*[B|b]est.*[M|m]otion|[P|p]icture.*[W|w]in.*[M|m]otion.*[D|d]rama.*[B|b]est.'\n",
    " \n",
    "    for i in range(0,len(df)):\n",
    "            xyz=(re.match(pattern,df.text[i]))\n",
    "            if(xyz):\n",
    "                a.append(df.text[i])\n",
    "    n=[]\n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "            axyz=nlp(a[i])\n",
    "            n.append(axyz.ents)\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3={}\n",
    "            \n",
    "    for j in range(0,len(n)):\n",
    "            for k in range(0,len(n[j])):\n",
    "                    str1.append(str(n[j][k]))\n",
    "                    \n",
    "    for i in str1:\n",
    "            if i not in str2:\n",
    "                    str2.append(i)\n",
    "    for y in range(0,len(str2)):\n",
    "            str3[str2[y]]=str1.count(str2[y]) \n",
    "\n",
    "\n",
    "    xyz=[]\n",
    "    movie=[]\n",
    "    xyz.append(url('https://www.imdb.com/list/ls058177122'))\n",
    "    for i in range(0,len(xyz)):\n",
    "        for j in range(0,len(xyz[i])):\n",
    "            movie.append((xyz[i][j].strip('\\n')).lower().strip(' '))\n",
    "    for i,j in str3.items():\n",
    "            if i.lower() in movie:\n",
    "                print(i,j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Motion picture musical or comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def musical_picture():\n",
    "    n=[]\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    pattern=r'[M|m]otion.*[P|p]icture.*[M|m]usical|[P|p]icture.*[M|m]usical.*[M|m]otion|[P|p]icture.*[M|m]otion.*[M|m]usical'\n",
    " \n",
    "    for i in range(0,len(df)):\n",
    "            xyz=(re.match(pattern,df.text[i]))\n",
    "            if(xyz):\n",
    "                a.append(df.text[i])\n",
    "    n=[]\n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "            axyz=nlp(a[i])\n",
    "            n.append(axyz.ents)\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3={}\n",
    "            \n",
    "    for j in range(0,len(n)):\n",
    "            for k in range(0,len(n[j])):\n",
    "                    str1.append(str(n[j][k]))\n",
    "                    \n",
    "    for i in str1:\n",
    "            if i not in str2:\n",
    "                    str2.append(i)\n",
    "    for y in range(0,len(str2)):\n",
    "            str3[str2[y]]=str1.count(str2[y]) \n",
    "\n",
    "\n",
    "    xyz=[]\n",
    "    movie=[]\n",
    "    xyz.append(url('https://www.imdb.com/list/ls058177122'))\n",
    "    for i in range(0,len(xyz)):\n",
    "        for j in range(0,len(xyz[i])):\n",
    "            movie.append((xyz[i][j].strip('\\n')).lower().strip(' '))\n",
    "    for i,j in str3.items():\n",
    "            if i.lower() in movie:\n",
    "                print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musical_picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best perfomance actor in motion picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_picture_drama():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'Drama.*Picture.*Actor|Picture.*Drama.*Actor|Actor.*Picture.*Drama'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>2500:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_picture_drama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best perfomance actress in motion picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_picture_drama():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Drama.*Picture.*Actress|Picture.*Drama.*Actress|Actress.*Picture.*Drama'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "   \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_picture_drama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Motion Picture Actor – Musical or Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_picture_musical():\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Musical.*Picture.*Actor|Picture.*Musical.*Actor|Actor.*Picture.*Musical'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>1500:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_picture_musical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Motion Picture Actress – Musical or Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_picture_musical():\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Musical.*Picture.*Actress|Picture.*Musical.*Actress|Actress.*Picture.*Musical'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_picture_musical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Motion Picture Supporting Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_picture_supporting():\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Supporting.*Actor.*Picture|Picture.*Supporting.*Actor|Actor.*Picture.*Supporting'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>500:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_picture_supporting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Motion Picture Supporting Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_picture_supporting():\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Supporting.*Actress.*Picture|Picture.*Supporting.*Actress|Actress.*Picture.*Supporting'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_picture_supporting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Director – Motion Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_picture():\n",
    "  \n",
    "    n=[]\n",
    "    pattern=r'[M|m]otion.*[P|p]icture.*[B|b]est.*[D|d]irector|[B|b]est.*[D|d]irector.*[M|m]otion.*[P|p]icture'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "\n",
    "        \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>900:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Screenplay – Motion Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def screenplay_picture():\n",
    "    n=[]\n",
    "    pattern=r'[M|m]otion.*[P|p]icture.*[B|b]est.*[S|s]creen.*[P|p]lay|[B|b]est.*[S|s]creen.*[P|p]lay.*[M|m]otion.*[P|p]icture'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])     \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screenplay_picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Original Score – Motion Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_score():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*[B|b]est.*[O|o]riginal.*[S|s]core|[S|s]core.*[O|o]riginal.*[B|b]est|[B|b]est.*[S|s]core.*[O|o]riginal'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])     \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            #if i.lower() in celeb:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Original Song – Motion Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_song():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[O|o]riginal.*[S|s]ong|[S|s]ong.*[O|o]riginal.*[B|b]est|[B|b]est.*[S|s]ong.*[O|o]riginal'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])     \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>2000:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_song()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best animated feature film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_film():\n",
    "    \n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[A|a]nimated.*[F|f]eature.*[F|f]ilm|[F|f]eature.*[F|f]ilm.*[A|a]nimated.*[B|b]est|[A|a]nimated.*[F|f]eature.*[F|f]ilm.*[B|b]est'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])      \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>500:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animated_film()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best foreign language film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreign_film():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[F|f]oreign.*[L|l]anguage.*[F|f]ilm|[F|f]oreign.*[L|l]anguage.*[F|f]ilm.*[B|b]est|[F|f]ilm.*[F|f]oreign.*[L|l]anguage.*[B|b]est'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "       \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>300:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_film()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best performance in television series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_drama():\n",
    "    \n",
    "    n=[]\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    pattern=r'.*[B|b]est.Television.[S|s]eries.*Drama'\n",
    " \n",
    "    for i in range(0,len(df)):\n",
    "            xyz=(re.match(pattern,df.text[i]))\n",
    "            if(xyz):\n",
    "                a.append(df.text[i])\n",
    "    n=[]\n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "            axyz=nlp(a[i])\n",
    "            n.append(axyz.ents)\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3={}\n",
    "            \n",
    "    for j in range(0,len(n)):\n",
    "            for k in range(0,len(n[j])):\n",
    "                    str1.append(str(n[j][k]))\n",
    "                    \n",
    "    for i in str1:\n",
    "            if i not in str2:\n",
    "                    str2.append(i)\n",
    "    for y in range(0,len(str2)):\n",
    "            str3[str2[y]]=str1.count(str2[y]) \n",
    "\n",
    "    for i,j in str4.items():\n",
    "        if j>600:\n",
    "            print(i,j)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_drama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series musical or comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def musical_series():\n",
    "    n=[]\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    pattern=r'.Best.*Television.*Series.*Musical.'\n",
    " \n",
    "    for i in range(0,len(df)):\n",
    "            xyz=(re.match(pattern,df.text[i]))\n",
    "            if(xyz):\n",
    "                a.append(df.text[i])\n",
    "    n=[]\n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "            axyz=nlp(a[i])\n",
    "            n.append(axyz.ents)\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3={}\n",
    "            \n",
    "    for j in range(0,len(n)):\n",
    "            for k in range(0,len(n[j])):\n",
    "                    str1.append(str(n[j][k]))\n",
    "                    \n",
    "    for i in str1:\n",
    "            if i not in str2:\n",
    "                    str2.append(i)\n",
    "    for y in range(0,len(str2)):\n",
    "            str3[str2[y]]=str1.count(str2[y]) \n",
    "    for i,j in str4.items():\n",
    "        if j>600:\n",
    "            print(i,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musical_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series actor- drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_series_drama():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*Drama.*Series.*Actor|Series.*Drama.*Actor|Actor.*Series.*Drama'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>1500:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_series_drama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series actress- Drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_series_drama():\n",
    "    import re\n",
    "    n=[]\n",
    "    pattern=r'[W|w]in.*Drama.*Series.*Actress|Series.*Drama.*Actress|Actress.*Series.*Drama'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>680:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_series_drama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series actor- musical or comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_series_musical():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[A|a]ctor.*[S|s]eries.*[M|m]usical|[A|a]ctor.*[B|b]est.*[S|s]eries.*[M|m]usical'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>1000:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_series_musical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best television series actress- musical or comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_series_musical():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[A|a]ctress.*[S|s]eries.*[M|m]usical|[A|a]ctress.*[B|b]est.*[S|s]eries.*[M|m]usical'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>600:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_series_musical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Miniseries or Television Film - Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_mini_series():\n",
    "    n=[]\n",
    "    pattern=r'.*[W|w]in.*[M|m]ini.*[S|s]eries.*[P|performance].*Actor|[M|m]ini.*[S|s]eries.*[P|performance].*Actor|Actor.*[P|performance].*[M|m]ini.*[S|s]eries'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>1000:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_mini_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performance in a Miniseries or Television Film - Actress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actress_mini_series():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*Series.*[P|performance].*Actress|Series.*[P|performance].*Actress|Actress.*[P|performance].*Series'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>100:\n",
    "            if i.lower() in celeb:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress_mini_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best miniseries or television film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_series_():\n",
    "    \n",
    "    n=[]\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    pattern=r'.*[W|w]in.*[B|b]est.*[M|m]ini.*[S|s]eries.*|[M|m]ini.*[S|s]eries.*[W|w]in.*[B|b]est|[M|m]ini.*[S|s]eries.*[W|w]in.*[B|b]est.*'\n",
    " \n",
    "    for i in range(0,len(df)):\n",
    "            xyz=(re.match(pattern,df.text[i]))\n",
    "            if(xyz):\n",
    "                a.append(df.text[i])\n",
    "    n=[]\n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "            axyz=nlp(a[i])\n",
    "            n.append(axyz.ents)\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3={}\n",
    "            \n",
    "    for j in range(0,len(n)):\n",
    "            for k in range(0,len(n[j])):\n",
    "                    str1.append(str(n[j][k]))\n",
    "                    \n",
    "    for i in str1:\n",
    "            if i not in str2:\n",
    "                    str2.append(i)\n",
    "    for y in range(0,len(str2)):\n",
    "            str3[str2[y]]=str1.count(str2[y]) \n",
    "    for i,j in str3.items():\n",
    "        if j==990:  # Since The Mini Series actor s name wasn't present on IMDB top 1000  list  we are taking the max count.\n",
    "                print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_series_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best performance in a supporting role in a series, miniseries or television film - Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniseries_supporting_actor():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[S|s]upporting.*[A|a]ctor.*[S|s]eries|[A|a]ctor.*[B|b]est.*[S|s]upporting.*[S|s]eries'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j>3000:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniseries_supporting_actor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best performance in a supporting role in a series, miniseries or television film - Actress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniseries_supporting_actress():\n",
    "    n=[]\n",
    "    pattern=r'[B|b]est.*[S|s]upporting.*[A|a]ctress.*[S|s]eries|[A|a]ctress.*[B|b]est.*[S|s]upporting.*[S|s]eries'\n",
    "    for i in range(0,len(df)):\n",
    "        if(re.search(pattern,df.text[i])):\n",
    "            axyz=nlp(df.text[i])\n",
    "            n.append(axyz.ents)\n",
    "    a=[]\n",
    "    str1=[]\n",
    "    str2=[]\n",
    "    str3=[]\n",
    "    str4={}\n",
    "        \n",
    "    for i in range(0,len(n)):\n",
    "        if n[i]!=[]:\n",
    "            for k in range(0,len(n[i])):\n",
    "                a=n[i][k]\n",
    "                if(a not in str2):\n",
    "                    \n",
    "                    str2.append(a)\n",
    "                                \n",
    "    sets=set()\n",
    "    str5=[]\n",
    "    for i in str2:\n",
    "        st1=i.text\n",
    "        str5.append(st1)\n",
    "        if i.text not in sets:\n",
    "                st=i.text            \n",
    "                str3.append(st)\n",
    "        sets.add(i.text)\n",
    "            \n",
    "        \n",
    "    for y in range(0,len(str3)):\n",
    "        \n",
    "        str4[str3[y]]=str5.count(str3[y])\n",
    "        \n",
    "\n",
    "    \n",
    "    for i,j in str4.items():\n",
    "        if j==934: # Since The Mini Series actor s name wasn't present on IMDB top 1000  list  we are taking the max count.\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniseries_supporting_actress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c202d9383f7107249c0f643a7ed5a566db1c001c784a242ad1b58e8a23c5346"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
